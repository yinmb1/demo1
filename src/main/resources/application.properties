spring.hello.msg = nihao
server.port=8022
# server.context-path=/springboot-demo
spring.application.name=demo-service-ymb
debug=false
spring.redis.host=172.30.3.184
spring.redis.port=6379
spring.redis.timeout=2000
spring.redis.database=1
maxIdle=300
maxActive=1000
maxWait=1000
spring.redis.pool.max-total=100
testOnBorrow=false
blockWhenExhausted=true
##数据库
spring.datasource.url=jdbc:mysql://172.****/***?useUnicode=true&characterEncoding=utf-8&allowMultiQueries=true&useSSL=false
spring.datasource.username=*****
spring.datasource.password=********
spring.datasource.driver-class-name:com.mysql.jdbc.Driver
# 使用druid数据源
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
# 下面为连接池的补充设置，应用到上面所有数据源中
# 初始化大小，最小，最大
spring.datasource.initialSize=5
spring.datasource.minIdle=5
spring.datasource.maxActive=20
# 配置获取连接等待超时的时间
spring.datasource.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.minEvictableIdleTimeMillis=300000
spring.datasource.validationQuery=SELECT 1 FROM DUAL
spring.datasource.testWhileIdle=true
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.poolPreparedStatements=true
spring.datasource.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.filters=stat,wall,log4j
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
# 合并多个DruidDataSource的监控数据
#spring.datasource.useGlobalDataSourceStat=true



## elasticsearch集群名称，默认的是elasticsearch
#spring.data.elasticsearch.cluster-name= elasticsearch_yy
##节点的地址 注意api模式下端口号是9300，千万不要写成9200
#spring.data.elasticsearch.cluster-nodes =127.0.0.1:9300
##是否开启本地存储
#spring.data.elasticsearch.repositories.enable=false


















mybatis.mapperLocations=classpath*:mapper/*.xml
####配置日志根Logger
#log4j.rootLogger=DEBUG,stdout,file
##ERROR 为严重错误 主要是程序的错误
##WARN 为一般警告，比如session丢失
##INFO 为一般要显示的信息，比如登录登出
##DEBUG 为程序的调试信息
#log4j.additivity.org.apache=true
#
####配置日志信息输出目的地Appender
#log4j.appender.stdout=org.apache.log4j.ConsoleAppender
##org.apache.log4j.ConsoleAppender（控制台）
##org.apache.log4j.FileAppender（文件）
##org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）
##org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）
##org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）
##log4j.appender.error.Target=System.out
####输出ERROR级别以上的日志
#log4j.appender.stdout.threshold=INFO
####配置日志信息的格式（布局）
#log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
##org.apache.log4j.HTMLLayout（以HTML表格形式布局）
##org.apache.log4j.PatternLayout（可以灵活地指定布局模式）
##org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）
##org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）
####配置日志打印的格式格式化日志信息
#log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n
#
##%m   输出代码中指定的消息
##%p   输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL
##%r   输出自应用启动到输出该log信息耗费的毫秒数
##%c   输出所属的类目，通常就是所在类的全名
##%t   输出产生该日志事件的线程名
##%n   输出一个回车换行符，Windows平台为“\r\n”，Unix平台为“\n”
##%d   输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss , SSS}
##%l   输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数
##log4j.appender.file=org.apache.log4j.RollingFileAppender
#log4j.appender.file=org.apache.log4j.DailyRollingFileAppender
#log4j.appender.file.layout=org.apache.log4j.PatternLayout
#log4j.appender.file.DatePattern='.'yyyy-MM-dd-HH-mm
## '.'yyyy-MM：每月
## '.'yyyy-ww：每周
## '.'yyyy-MM-dd：每天
## '.'yyyy-MM-dd-a：每天两次
## '.'yyyy-MM-dd-HH：每小时
## '.'yyyy-MM-dd-HH-mm：每分钟
##log4j.appender.file.MaxFileSize=1MB
####滚动文件的最大数
##log4j.appender.file.MaxBackupIndex=8
#log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} [%-5p](%-30c{1}) [TxId : %X{PtxId} , SpanId : %X{PspanId}] [ET:%X{ENV_TYPE},AN:%X{APP_NAME},SN:%X{SERVICE_NAME},CN:%X{CONTAINER_NAME},CI:%X{CONTAINER_IP}] %m%n
#log4j.appender.file.Threshold=DEBUG
####将消息增加到指定文件中,false指将消息覆盖指定的文件内容
#log4j.appender.file.append=true
####日志的保存位置
##log4j.appender.file.File=E:/logs/file-debug-log.log
#log4j.appender.file.File=E:/logs/debug-debug.log
####每天产生一个日志文件
##log4j.appender.file=org.apache.log4j.DailyRollingFileAppender
##log4j.appender.file.layout=org.apache.log4j.PatternLayout
##log4j.appender.file.maxFileSize=100
##log4j.appender.file.maxBackupIndex=5
##log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} [%-5p](%-30c{1}) [TxId : %X{PtxId} , SpanId : %X{PspanId}] [ET:%X{ENV_TYPE},AN:%X{APP_NAME},SN:%X{SERVICE_NAME},CN:%X{CONTAINER_NAME},CI:%X{CONTAINER_IP}] %m%n
##log4j.appender.file.Threshold=DEBUG
##log4j.appender.file.append=true
##log4j.appender.file.File=E:/logs/debug-log.log
logging.level.root=info
logging1.path=E:/logs/ymb
# 配置pageHelper分页插件的内容
pagehelper.helper-dialect=mysql
pagehelper.reasonable=true
pagehelper.support-methods-arguments=true
pagehelper.params=count=countSql
#------------------------------------RabbitMQ基本配置
# RabbitMQ的主机地址(默认为:localhost)

# 指定该用户要连接到的虚拟host端(注:如果不指定,那么默认虚拟host为“/”)
#spring.rabbitmq.virtual-host=/vhost_A
# amqp协议端口号:5672; 集群端口号:25672;http端口号:15672;

#------------------------------------RabbitMQ可选配置(注:这里只用到了特别少的几个)
# broker端没有收到消费者的ACK(即:消费者异常时)时,是否再次向消费者投递消息(默认为false)
# 为false时，如果没有收到消费者的ACK，那么会无限投递;设置为true时,默认投递时次数为3此
#spring.rabbitmq.listener.simple.retry.enabled=true
# 设置向消费者投递消息的最大次数
#spring.rabbitmq.listener.simple.retry.max-attempts=2
# 投递消息的间隔(单位ms)
#spring.rabbitmq.listener.simple.retry.initial-interval=2000


spring.rabbitmq.host=127.0.0.1
spring.rabbitmq.port=5672
spring.rabbitmq.username=guest
spring.rabbitmq.password=guest
